# üßÆ Hoja de Apuntes - Modelaci√≥n Num√©rica (2025 - 2C)

## Unidad 1: Errores

### üîπ Tipos de Errores
- **Error absoluto:** \( e_a = |x - x_{real}| \)
- **Error relativo:** \( e_r = \frac{e_a}{|x_{real}|} \)
- **Error porcentual:** \( e_p = e_r \times 100 \)

### üîπ Propagaci√≥n de errores
| Caso | Error inherente | Error redondeo | Error discretizaci√≥n | Error final |
|------|------------------|----------------|-------------------------|--------------|
| I | Nulo | Nulo | Nulo | Nulo |
| II | No nulo | Nulo | Nulo | Depende del problema num√©rico |
| III | Nulo | No nulo | Nulo | Depende del algoritmo |
| IV | Nulo | Nulo | No nulo | Error de discretizaci√≥n |

### üîπ Cifras significativas
- Son los n√∫meros que expresan la precisi√≥n de una medici√≥n.
- Ejemplo: 0,020 ‚Üí 2 cifras significativas.

---

## Unidad 2: Ecuaciones no lineales

### üî∏ M√©todo de Bisecci√≥n
**Objetivo:** Encontrar una ra√≠z de \( f(x) = 0 \) en [a, b].

**Condici√≥n:** \( f(a) \times f(b) < 0 \)

**F√≥rmula:**
\[
 x_r = \frac{a + b}{2}
\]

**Procedimiento:**
1. Calcular \( x_r \)
2. Evaluar \( f(x_r) \)
3. Si \( f(a)f(x_r) < 0 \Rightarrow b = x_r \), si no \( a = x_r \)
4. Repetir hasta que \( |b - a| < tol \)

**Orden de convergencia:** lineal.

---

### üî∏ M√©todo de Regula-Falsi (Falsa Posici√≥n)
**F√≥rmula:**
\[
 x_r = b - f(b) \frac{(a - b)}{f(a) - f(b)}
\]

**Igual proceso** que bisecci√≥n pero reemplaza el punto medio por esta f√≥rmula. Converge m√°s r√°pido, pero sigue siendo lineal.

---

### üî∏ M√©todo del Punto Fijo
**Reescritura:** \( x = g(x) \)

**Iteraci√≥n:** \( x_{k+1} = g(x_k) \)

**Condici√≥n de convergencia:** \( |g'(x)| < 1 \) cerca de la ra√≠z.

**Orden de convergencia:** lineal.

---

### üî∏ M√©todo de Newton-Raphson
**F√≥rmula:**
\[
 x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}
\]

**Condiciones:**
- f y f' deben ser continuas.
- \( f'(x) \neq 0 \).

**Orden de convergencia:** cuadr√°tica.

**Variables:**
- \( x_k \): aproximaci√≥n actual
- \( f(x_k) \): valor de la funci√≥n
- \( f'(x_k) \): derivada de la funci√≥n

---

### üî∏ M√©todo de la Secante
**F√≥rmula:**
\[
 x_{k+1} = x_k - f(x_k) \frac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})}
\]

**No requiere derivada.**
**Orden de convergencia:** \( \approx 1.618 \) (superlineal).

---

### üî∏ Newton-Raphson para ra√≠ces m√∫ltiples
**F√≥rmula:**
\[
 x_{k+1} = x_k - \frac{f(x_k) f'(x_k)}{[f'(x_k)]^2 - f(x_k)f''(x_k)}
\]

**Orden de convergencia:** cuadr√°tica si la ra√≠z es simple, lineal si es m√∫ltiple.

---

### üî∏ Orden de convergencia
\[
\lim_{k \to \infty} \frac{|x_{k+1} - r|}{|x_k - r|^p} = C
\]

Donde:
- \( p \): orden de convergencia (1 = lineal, 2 = cuadr√°tica)
- \( C \): constante de convergencia

---

## Unidad 3: Ajuste de Curvas

### üî∏ Ajuste por cuadrados m√≠nimos (lineal)
Queremos ajustar una recta: \( y = a + bx \)

**F√≥rmulas:**
\[
 b = \frac{n\sum xy - (\sum x)(\sum y)}{n\sum x^2 - (\sum x)^2}
\]
\[
 a = \bar{y} - b\bar{x}
\]

**Error cuadr√°tico medio (ECM):**
\[
 ECM = \frac{1}{n}\sum (y_i - (a + bx_i))^2
\]

---

### üî∏ Ajuste cuadr√°tico y c√∫bico
- Cuadr√°tico: \( y = a + bt + ct^2 \)
- C√∫bico: \( y = a + bt + ct^2 + dt^3 \)

Coeficientes se obtienen con matrices normales (\( A^T A x = A^T y \)) o `np.polyfit(x, y, grado)`.

---

### üî∏ Ajuste exponencial
\[
 y = e^{a - bt}
\]
Tomando logaritmos:
\[
 \ln(y) = a - bt
\]
Aplicar regresi√≥n lineal entre \( t \) y \( \ln(y) \).

---

### üî∏ Interpolaci√≥n polin√≥mica
Usa los puntos exactos para que el polinomio pase por ellos.

#### Polinomio de Lagrange:
\[
 P(x) = \sum_{i=0}^{n} y_i L_i(x), \quad L_i(x) = \prod_{j \neq i} \frac{x - x_j}{x_i - x_j}
\]

#### Polinomio de Newton:
Usa diferencias divididas.
\[
 P(x) = a_0 + a_1(x - x_0) + a_2(x - x_0)(x - x_1) + \ldots
\]

**Error de interpolaci√≥n:**
\[
E(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!}\prod_{i=0}^{n}(x - x_i)
\]

#### Nodos de Chebyshev:
Distribuyen los puntos para minimizar el error de oscilaci√≥n (fen√≥meno de Runge).
\[
 x_i = \cos\left(\frac{2i+1}{2n+2}\pi\right), \quad i = 0,1,...,n
\]

#### Polinomio de Hermite:
Interpola usando valores y derivadas conocidas.

---

## Unidad 5: Diferenciaci√≥n e Integraci√≥n Num√©rica

### üî∏ Diferenciaci√≥n num√©rica
#### Aproximaciones:
\[
 f'(x) \approx \frac{f(x+h) - f(x)}{h} \quad \text{(diferencia hacia adelante)}
\]
\[
 f'(x) \approx \frac{f(x) - f(x-h)}{h} \quad \text{(diferencia hacia atr√°s)}
\]
\[
 f'(x) \approx \frac{f(x+h) - f(x-h)}{2h} \quad \text{(centrada)}
\]

**Error de truncamiento:** \( O(h) \) o \( O(h^2) \) seg√∫n el m√©todo.

---

### üî∏ Integraci√≥n num√©rica

#### Regla del trapecio:
\[
 I = \frac{h}{2} [f(x_0) + 2\sum_{i=1}^{n-1} f(x_i) + f(x_n)]
\]
**Error:** \( E_t = -\frac{(b-a)h^2}{12}f''(\xi) \)

#### Regla de Simpson 1/3:
\[
 I = \frac{h}{3} [f(x_0) + 4f(x_1) + 2f(x_2) + \ldots + 4f(x_{n-1}) + f(x_n)]
\]
**Error:** \( E_t = -\frac{(b-a)h^4}{180}f^{(4)}(\xi) \)

#### Regla de Simpson 3/8:
\[
 I = \frac{3h}{8}[f(x_0) + 3f(x_1) + 3f(x_2) + 2f(x_3) + ... + f(x_n)]
\]

#### Richardson (mejora de estimaci√≥n):
\[
 R = T(h_2) + \frac{T(h_2) - T(h_1)}{(h_1/h_2)^p - 1}
\]
Donde \( p \) es el orden del m√©todo.

---

‚úÖ **Consejos generales:**
- Verificar siempre continuidad de f(x) y derivadas antes de aplicar Newton.
- Normalizar variables antes de ajustar.
- Revisar tolerancia y error relativo en iteraciones.
- Usar Chebyshev cuando se interpola con muchos puntos.

---
**Fin de la hoja de apuntes** ‚ú®

